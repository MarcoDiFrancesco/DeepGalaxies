{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["import torch\n","from pathlib import Path\n","import os\n","from torch import nn\n","\n","self.galaxy_names = {\n","    0: \"Edge-on without Bulge\",\n","    1: \"Unbarred Tight Spiral\",\n","    2: \"Edge-on with Bulge\",\n","    3: \"Merging\",\n","    4: \"In-between Round Smooth\",\n","    5: \"Barred Spiral\",\n","    6: \"Disturbed\",\n","    7: \"Unbarred Loose Spiral\",\n","    8: \"Cigar Shaped Smooth\",\n","    9: \"Round Smooth\",\n","}\n","\n","class MyDataset:\n","    def __init__(self, dataset_type):\n","        self.ds_type = dataset_type\n","        self.ds_dir = Path('/') / \"kaggle\" / \"input\" / \"galaxies\" / \"dataset\" / ds_type\n","\n","        self.images = [f for f in self.dest_dir.iterdir()]\n","        print(f\"Dataset of {len(self.images)} images loaded\")\n","\n","    def get_split(self, train_len):\n","        train_len = int(train_len*len(self))\n","        valid_len = len(self) - train_len\n","        return torch.utils.data.random_split(self, [train_len, valid_len])\n","        \n","    def __getitem__(self, index):\n","        f = self.images[index]\n","        img = np.load(f)\n","        # Only for train augment\n","        if self.ds_type == \"train\":\n","            pass\n","            #preprocess = transforms.Compose([\n","            #    transforms.Resize(256),\n","            #    transforms.CenterCrop(224),\n","            #    transforms.ToTensor(),\n","            #    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","            #])\n","            #img = preprocess(img)\n","\n","        # For train/validation idx is the id (e.g. 3678)\n","        # For test idx is galaxy (from 0 to 9)\n","        idx = int(f_name.stem)\n","        print(\"TODO: is it right???\", idx)\n","        return (img, idx)\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","\n","class Operation(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv = nn.Conv2d(\n","            in_channels=in_channels,\n","            out_channels=out_channels,\n","            kernel_size=3,\n","            stride=1,\n","            padding=1,\n","        )\n","        self.batchnorm = nn.BatchNorm2d(num_features=out_channels)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.batchnorm(x)\n","        x = self.relu(x)\n","        return x\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        in_channels = 3\n","        n_classes = 10\n","        self.down = nn.Sequential(\n","            Operation(3, 64),\n","            Operation(64, 64),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            Operation(64, 128),\n","            Operation(128, 128),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            Operation(128, 256),\n","            Operation(256, 256),\n","            Operation(256, 256),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            Operation(256, 512),\n","            Operation(512, 512),\n","            Operation(512, 512),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            Operation(512, 512),\n","            Operation(512, 512),\n","            Operation(512, 512),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","        )\n","        self.fully_connected = nn.Sequential(\n","            # 512*8*8: channels*image size maxpolled 5 times\n","            # 4096: is fixed by the authors\n","            nn.Linear(512*8*8, 4096),\n","            nn.ReLU(True), # In place True\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(4096, n_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.down(x)\n","        # From [batch, 512, 8, 8] to [batch, 32768]\n","        x = x.reshape(x.shape[0], -1)\n","        x = self.fully_connected(x)\n","        return x\n","\n","class Trainer:\n","    def __init__(self):\n","        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        # Old model checkpoint\n","        model_path = Path('/') / \"kaggle\" / \"input\" / \"galaxies\" / \"model.ckpt\"\n","        # New model checkpoint\n","        self.dir_weights = Path(\"/\") / \"kaggle\" / \"working\"\n","        self.dir_weights.mkdir(exist_ok=True)\n","        # Load model checkpoint\n","        if os.path.isfile(model_path):\n","            self.model = torch.load(model_path)\n","            print(\"Using pre-trained weights\")\n","        else:\n","            self.model = Net().to(self.device)\n","            print(\"Training from scratch\")\n","        self.lr = 1e-5\n","        self.loss_fn = nn.CrossEntropyLoss()\n","        # TODO: TRY ADAM\n","        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr) # weight_decay=1e-5\n","        self.epochs = 20\n","        self.dataset = MyDataset(\"train\")\n","        # Dataset 80 / 20 split\n","        self.train_ds, self.valid_ds = self.dataset.get_split(0.8)\n","        self.train_dl = DataLoader(self.train_ds, batch_size=32, shuffle=True)\n","        self.valid_dl = DataLoader(self.valid_ds, batch_size=32)\n","        # Stats and Checkpoints directory\n","        self.losses = []\n","        self.accuracies = []\n","\n","\n","    def train(self):\n","        for epoch in range(self.epochs):\n","            correct_t, loss_t = self.train_epoch()\n","            correct_v, loss_v, _ = self.valid_epoch(self.valid_dl)\n","            # Save model\n","            torch.save(self.model, self.dir_weights / \"model.ckpt\")\n","            # Stats\n","            self.losses.append((loss_t, loss_v))\n","            self.accuracies.append((correct_t, correct_v))\n","            print(f\"Epoch {epoch+1:>3}/{self.epochs} - Train accuracy {correct_t:5.2f}% loss {loss_t:8f} - Valid accuracy {correct_v:5.2f}% loss {loss_v:8f}\")\n","\n","    def train_epoch(self):\n","        size = len(self.train_dl.dataset)\n","        loss_value, correct = 0, 0\n","        for batch, (inputs, labels) in enumerate(self.train_dl):\n","            print(f\"Train batch: {batch:>3}/{len(self.train_dl):<3}\", end='\\r')\n","            # Transfer to CPU or GPU\n","            inputs, labels = inputs.to(self.device), labels.to(self.device)\n","            # Set gradients to zero\n","            self.optimizer.zero_grad()\n","            # Get predictions\n","            pred = self.model(inputs)\n","            # Calculate loss\n","            loss = self.loss_fn(pred, labels)\n","            loss_value += loss.item()\n","            # Compare predictions with real values\n","            values = pred.argmax(1) == labels\n","            # Get how many are true\n","            correct += values.sum().item()\n","            # Backpropagation\n","            loss.backward()\n","            self.optimizer.step()\n","        accuracy = (correct / size) * 100\n","        loss_value /= size\n","        return accuracy, loss_value\n","    \n","    def valid_epoch(self, dataloader):\n","        \"\"\"\n","        Validation function\n","        \"\"\"\n","        # Swith layers\n","        self.model.eval()\n","        loss, correct = 0, 0\n","        size_by_label = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n","        correct_by_label = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n","        with torch.no_grad():\n","            # For each batch\n","            for batch, (inputs, labels) in enumerate(dataloader):\n","                print(f\"Valid batch: {batch:>3}/{len(dataloader):<3}\", end='\\r')\n","                inputs, labels = inputs.to(self.device), labels.to(self.device)\n","                pred = self.model(inputs)\n","                loss += self.loss_fn(pred, labels).item()\n","                # Compare predictions with real values\n","                for pred, real in zip(pred.argmax(1), labels):\n","                    # TODO: find a nicer way to get prediction from tensor\n","                    galaxy_num = int(real)\n","                    size_by_label[galaxy_num] += 1\n","                    if pred == real:\n","                        # Compute per label accuracy\n","                        correct_by_label[galaxy_num] += 1\n","                        correct += 1\n","        size = len(dataloader.dataset)\n","        accuracy = (correct / size) * 100\n","        loss /= size\n","        for key, value in correct_by_label.items():\n","            correct_by_label[key] /= size_by_label[key] if size_by_label[key] else 1\n","            # Transform in percentage\n","            correct_by_label[key] *= 100\n","        return accuracy, loss, correct_by_label\n","\n","    def test_epoch(self, dataloader):\n","        \"\"\"\n","        Test function\n","        \"\"\"\n","        predictions = []\n","        self.model.eval()\n","        with torch.no_grad():\n","            for batch, (inputs, f_names) in enumerate(dataloader):\n","                print(f\"Test batch: {batch:>3}/{len(dataloader):<3}\", end='\\r')\n","                inputs = inputs.to(self.device)\n","                pred = self.model(inputs)\n","                for pred, f_name in zip(pred.argmax(1), f_names):\n","                    # TODO: find a nicer way to get prediction from tensor\n","                    pred = int(pred)\n","                    f_name = int(f_name)\n","                    predictions.append((pred, f_name))\n","        return predictions\n","\n","trainer = Trainer()\n","print(trainer.galaxy_names)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot images by type\n","images_dir = trainer.dataset.dest_dir\n","img_by_type = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}\n","for img_name in os.listdir(images_dir):\n","    # e.g. 3\n","    img_type = int(img_name[:1])\n","    img_by_type[img_type].append(img_name)\n","\n","rows = 2 # 1 removes the dimention\n","fig, ax = plt.subplots(rows, 10, figsize=(40, 4*rows))\n","fig.suptitle('Image examples')\n","for i in range(10):\n","    for j in range(rows):\n","        img = img_by_type[i][j]\n","        img = np.load(images_dir / img)\n","        img = np.transpose(img, (2, 1, 0))\n","        title = i\n","        ax[j][i].set_title(title)\n","        ax[j][i].imshow(img)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#trainer.train()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot loss and accuracy\n","fig, (ax1, ax2) = plt.subplots(2, figsize=(10,11))\n","# Get image sample\n","img_size = trainer.train_ds[0][0].shape\n","fig.suptitle(f'VGG16 - Image size: {img_size} - LR: {trainer.lr}')\n","epochs = list(range(1, trainer.epochs + 1))\n","#epochs = list(range(1, 12))\n","train, test = ax1.plot(epochs, trainer.losses, label='test')\n","ax1.set_title('Loss')\n","ax1.legend((train, test), (\"Train\", \"Test\"))\n","ax1.set_xlabel('Epochs')\n","ax1.set_ylabel('Loss')\n","\n","train, test = ax2.plot(epochs, trainer.accuracies, label='test2')\n","ax2.set_title('Accuracy')\n","ax2.legend((train, test), (\"Train\", \"Test\"))\n","ax2.yaxis.set_major_formatter(mtick.PercentFormatter())\n","ax2.set_xlabel('Epochs')\n","ax2.set_ylabel('Accuracy')\n","plt.show()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print train and validation perfornces by galaxy\n","def print_stats(acc, loss, accuracy_by_label):\n","    print(f\"Accuracy {acc:.2f}%    \")\n","    print(f\"Loss {loss:8f}\")\n","    for key, value in accuracy_by_label.items():\n","        galaxy_name = trainer.dataset.galaxy_names[key]\n","        print(f\"- {value:5.1f}% <- {galaxy_name}\")\n","\n","print(f\"--- Train dataset ---\")\n","acc, loss, accuracy_by_label = trainer.valid_epoch(trainer.train_dl)\n","print_stats(acc, loss, accuracy_by_label)\n","print(f\"--- Valid dataset ---\")\n","acc, loss, accuracy_by_label = trainer.valid_epoch(trainer.valid_dl)\n","print_stats(acc, loss, accuracy_by_label)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = MyDataset(\"test\")\n","test_dl = DataLoader(dataset, batch_size=32)\n","predictions = trainer.test_epoch(test_dl)\n","predictions_new = []\n","for pred, f_name in predictions:\n","    # From 5 to Barred Spiral\n","    pred = trainer.dataset.galaxy_names[pred]\n","    predictions_new.append((f_name, pred))\n","\n","# Sort by filename\n","predictions_new = sorted(predictions_new, key=lambda x: x[0])\n","\n","with open('output.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(predictions_new)\n","print(\"\\nDone!\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}